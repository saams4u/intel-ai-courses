{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Methods Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be using the wine quality data set for these exercises. This data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data`.\n",
    "\n",
    "We will be using the chemical properties (i.e. everything but quality and color) to cluster the wine. Though this is unsupervised learning, it can be fun to see how our clustering results map onto color and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Import the data and examine the features. \n",
    "* Note which are continuous, categorical, and boolean. \n",
    "* How many entries are there for the two colors and range of qualities? \n",
    "* Make a histogram plot of the quality for each of the wine colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:10:48.585240Z",
     "start_time": "2017-03-20T08:10:48.548076-04:00"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "filepath = os.sep.join(data_path + ['Wine_Quality_Data.csv'])\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "data.head(4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:09:58.538878Z",
     "start_time": "2017-03-20T08:09:58.531714-04:00"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types for each entry. The implementation of K-means in Scikit-learn is designed only to work with continuous data (even though it is sometimes used with categorical or boolean types). Fortunately, all the columns we will be using (everything except quality and color) are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:12:23.585637Z",
     "start_time": "2017-03-20T08:12:23.576416-04:00"
    }
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of entries for each wine color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T12:10:32.347631Z",
     "start_time": "2017-03-20T08:10:32.337545-04:00"
    }
   },
   "outputs": [],
   "source": [
    "data.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of quality values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T13:00:49.509254Z",
     "start_time": "2017-03-20T09:00:49.495394-04:00"
    }
   },
   "outputs": [],
   "source": [
    "data.quality.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T13:05:20.809064Z",
     "start_time": "2017-03-20T09:05:20.584910-04:00"
    }
   },
   "outputs": [],
   "source": [
    "# seaborn styles\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "# custom colors\n",
    "red = sns.color_palette()[2]\n",
    "white = 'gray'\n",
    "\n",
    "# set bins for histogram\n",
    "bin_range = np.array([3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# plot histogram of quality counts for red and white wines\n",
    "ax = plt.axes()\n",
    "for color, plot_color in zip(['red', 'white'], [red, white]):\n",
    "    q_data = data.loc[data.color==color, 'quality']\n",
    "    q_data.hist(bins=bin_range, \n",
    "                alpha=0.5, ax=ax, \n",
    "                color=plot_color, label=color)\n",
    "    \n",
    "\n",
    "ax.legend()\n",
    "ax.set(xlabel='Quality', ylabel='Occurrence')\n",
    "\n",
    "# force tick labels to be in middle of region\n",
    "ax.set_xlim(3,10)\n",
    "ax.set_xticks(bin_range+0.5)\n",
    "ax.set_xticklabels(bin_range);\n",
    "ax.grid('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Example the correlation and skew of the relevant variables--everything except color and quality.\n",
    "* Perform any appropriate feature transformations and/or scaling.\n",
    "* Examine the pairwise distribution of the variables with pairplots to verify scaling and normalization efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = [x for x in data.columns if x not in ['color', 'quality']]\n",
    "\n",
    "# The correlation matrix\n",
    "corr_mat = data[float_columns].corr()\n",
    "\n",
    "# Strip out the diagonal values for the next step\n",
    "for x in range(len(float_columns)):\n",
    "    corr_mat.iloc[x,x] = 0.0\n",
    "    \n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise maximal correlations\n",
    "corr_mat.abs().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an examination of the skew values in anticipation of transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_columns = (data[float_columns]\n",
    "                .skew()\n",
    "                .sort_values(ascending=False))\n",
    "\n",
    "skew_columns = skew_columns.loc[skew_columns > 0.75]\n",
    "skew_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform log transform on skewed columns\n",
    "for col in skew_columns.index.tolist():\n",
    "    data[col] = np.log1p(data[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "data[float_columns] = sc.fit_transform(data[float_columns])\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the pairplot of the transformed and scaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.pairplot(data[float_columns + ['color']], \n",
    "             hue='color', \n",
    "             hue_order=['white', 'red'],\n",
    "             palette={'red':red, 'white':'gray'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "* Fit a K-means clustering model with two clusters.\n",
    "* Examine the clusters by wine color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:09.017663Z",
     "start_time": "2017-03-19T21:59:08.896993-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#from sklearn.cluster import cluster\n",
    "\n",
    "km = KMeans(n_clusters=2, random_state=42)\n",
    "km = km.fit(data[float_columns])\n",
    "\n",
    "data['kmeans'] = km.predict(data[float_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:09.332043Z",
     "start_time": "2017-03-19T21:59:09.315410-04:00"
    }
   },
   "outputs": [],
   "source": [
    "(data[['color','kmeans']]\n",
    " .groupby(['color','kmeans'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "* Now fit K-Means models with cluster values ranging from 1 to 20.\n",
    "* For each model, store the number of clusters and the inertia value. \n",
    "* Plot cluster number vs inertia. Does there appear to be an ideal cluster number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:21.588328Z",
     "start_time": "2017-03-19T21:59:12.450288-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create and fit a range of models\n",
    "km_list = list()\n",
    "\n",
    "for clust in range(1,5):\n",
    "    km = KMeans(n_clusters=clust, random_state=42)\n",
    "    km = km.fit(data[float_columns])\n",
    "    \n",
    "    km_list.append(pd.Series({'clusters': clust, \n",
    "                              'inertia': km.inertia_,\n",
    "                              'model': km}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T01:59:21.775524Z",
     "start_time": "2017-03-19T21:59:21.589747-04:00"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = (pd.concat(km_list, axis=1)\n",
    "             .T\n",
    "             [['clusters','inertia']]\n",
    "             .set_index('clusters'))\n",
    "\n",
    "ax = plot_data.plot(marker='o',ls='-')\n",
    "ax.set_xticks(range(0,21,2))\n",
    "ax.set_xlim(0,21)\n",
    "ax.set(xlabel='Cluster', ylabel='Inertia');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "* Fit an agglomerative clustering model with two clusters.\n",
    "* Compare the results to those obtained by K-means with regards to wine color.\n",
    "* Visualize the dendrogram produced by agglomerative clustering. *Hint:* SciPy has a module called [`cluster.hierarchy`](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html#module-scipy.cluster.hierarchy) that contains the `linkage` and `dendrogram` functions required to create the linkage map and plot the resulting dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:30:31.254165Z",
     "start_time": "2017-03-20T07:30:27.894864-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "ag = AgglomerativeClustering(n_clusters=2, linkage='ward', compute_full_tree=True)\n",
    "ag = ag.fit(data[float_columns])\n",
    "data['agglom'] = ag.fit_predict(data[float_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cluster assignment is arbitrary, the respective primary cluster numbers for red and white may not be identical to the ones below and also may not be the same for both K-means and agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:46:08.938224Z",
     "start_time": "2017-03-20T07:46:08.924114-04:00"
    }
   },
   "outputs": [],
   "source": [
    "(data[['color','agglom','kmeans']]\n",
    " .groupby(['color','agglom','kmeans'])\n",
    " .size()\n",
    " .to_frame()\n",
    " .rename(columns={0:'number'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the cluster numbers are not necessarily identical, the clusters are very consistent within a single wine variety (red or white).\n",
    "\n",
    "And here is a plot of the dendrogram created from agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-20T11:53:03.838928Z",
     "start_time": "2017-03-20T07:53:02.088506-04:00"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from matplotlib import colors\n",
    "\n",
    "Z = hierarchy.linkage(ag.children_, method='ward')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "# Some color customization\n",
    "dark_palette = sns.color_palette()\n",
    "red = colors.to_hex(dark_palette[2])\n",
    "blue = colors.to_hex(dark_palette[0])\n",
    "\n",
    "hierarchy.set_link_color_palette([red, 'gray'])\n",
    "\n",
    "den = hierarchy.dendrogram(Z, orientation='top', \n",
    "                           p=30, truncate_mode='lastp',\n",
    "                           show_leaf_counts=True, ax=ax,\n",
    "                           above_threshold_color=blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 6\n",
    "\n",
    "In this question, we are going to explore clustering as a form of feature engineering.\n",
    "\n",
    "* Create a **binary** target variable `y`, denoting if the quality is greater than 7 or not.\n",
    "* Create a variable called `X_with_kmeans` from `data`, by dropping the columns \"quality\", \"color\" and \"agglom\" from the dataset. Create `X_without_kmeans` from that by dropping \"kmeans\".\n",
    "* For both datasets, using `StratifiedShuffleSplit` with 10 splits, fit 10 Random Forest Classifiers and average out the roc-auc scores.\n",
    "* Compare the average roc-auc scores for the models using the kmeans clusters as a feature and the one that doesn't use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "y = (data['quality'] > 7).astype(int)\n",
    "X_with_kmeans = data.drop(['agglom', 'color', 'quality'], axis=1)\n",
    "X_without_kmeans = X_with_kmeans.drop('kmeans', axis=1)\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=6532)\n",
    "\n",
    "\n",
    "def get_avg_roc_10splits(estimator, X, y):\n",
    "    roc_auc_list = []\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        estimator.fit(X_train, y_train)\n",
    "        y_predicted = estimator.predict(X_test)\n",
    "        y_scored = estimator.predict_proba(X_test)[:, 1]\n",
    "        roc_auc_list.append(roc_auc_score(y_test, y_scored))\n",
    "    return np.mean(roc_auc_list)\n",
    "# return classification_report(y_test, y_predicted)\n",
    "\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "roc_with_kmeans = get_avg_roc_10splits(estimator, X_with_kmeans, y)\n",
    "roc_without_kmeans = get_avg_roc_10splits(estimator, X_without_kmeans, y)\n",
    "print(\"Without kmeans cluster as input to Random Forest, roc-auc is \\\"{0}\\\"\".format(roc_without_kmeans))\n",
    "print(\"Using kmeans cluster as input to Random Forest, roc-auc is \\\"{0}\\\"\".format(roc_with_kmeans))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore if the number of clusters have an effect in this improvement.\n",
    "\n",
    "* Create the basis training set from `data` by restricting to float_columns.\n",
    "* For $n = 1, \\ldots, 20$, fit a kmeans algotihm with n clusters. One hot encode it and add it to the **basis** training set. Don't add it to the previous iteration.\n",
    "* Fit 10 **Logistic Regression** models and compute the average roc-auc-score.\n",
    "* Plot the average roc-auc scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_basis = data[float_columns]\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=6532)\n",
    "\n",
    "\n",
    "def create_kmeans_columns(n):\n",
    "    km = KMeans(n_clusters=n)\n",
    "    km.fit(X_basis)\n",
    "    km_col = pd.Series(km.predict(X_basis))\n",
    "    km_cols = pd.get_dummies(km_col, prefix='kmeans_cluster')\n",
    "    return pd.concat([X_basis, km_cols], axis=1)\n",
    "\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "ns = range(1, 21)\n",
    "roc_auc_list = [get_avg_roc_10splits(estimator, create_kmeans_columns(n), y)\n",
    "                for n in ns]\n",
    "\n",
    "\n",
    "# seaborn styles\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.plot(ns, roc_auc_list)\n",
    "ax.set(\n",
    "    xticklabels= ns,\n",
    "    xlabel='number of clusters as features',\n",
    "    ylabel='average roc-auc over 10 iterations',\n",
    "    title='KMeans + LogisticRegression'\n",
    ")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Let's now explore on DBSCAN clustering method and if the number of samples have an effect in this improvement.\n",
    "\n",
    "* Create the basis training set from `data` by restricting to float_columns.\n",
    "* For $n = 1, \\ldots, 20$, fit a kmeans algotihm with n clusters. One hot encode it and add it to the **basis** training set. Don't add it to the previous iteration.\n",
    "* Fit 10 **Logistic Regression** models and compute the average roc-auc-score.\n",
    "* Plot the average roc-auc scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Let's now explore on Birch clustering method and if the number of clusters have an effect in this improvement.\n",
    "\n",
    "* Create the basis training set from `data` by restricting to float_columns.\n",
    "* For $n = 1, \\ldots, 20$, fit a kmeans algotihm with n clusters. One hot encode it and add it to the **basis** training set. Don't add it to the previous iteration.\n",
    "* Fit 10 **Logistic Regression** models and compute the average roc-auc-score.\n",
    "* Plot the average roc-auc scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
