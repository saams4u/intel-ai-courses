{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Recommending Text Articles with Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We'll be using the same datasets from last week to attack using topic modeling to build out recommendation systems. Essentially, we'll be asking the machine to \"read\" the documents and decide which documents are most like one-another. Let's start by getting the Fetch20 data and grabbing 3 of the categories - starting small. You can see the full list of available categories here: http://scikit-learn.org/stable/datasets/twenty_newsgroups.html. \n",
    "\n",
    "## Question 1\n",
    "\n",
    "* Load ONLY the training set from each of these categories \n",
    "* Remove the headers, footers, and quotes from each member of the set\n",
    "* Vectorize the dataset, once with CountVectorizer and once with TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "from sklearn import datasets\n",
    "\n",
    "categories = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball']\n",
    "\n",
    "# student section here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# student section here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "* Train both LSA and NMF based models with the vectorized data. If you can, use both CountVectorizer and TF-IDF Vectorized data. (In sklearn, LSA is called TruncatedSVD since it can serve many purposes!)\n",
    "* Print out your topics and their top 10 associated words. Do they make sense? Are they different for LSA vs NMF? How many topics do we need in order to make sure our Latent Space is understanding all the input document flavors?\n",
    "* Make sure to save the vectors for the training documents after they're transformed into the latent space, we'll need them in Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "\n",
    "# student section here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "display_topics(lsa_tfidf,count_vectorizer.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "display_topics(lsa_cv,count_vectorizer.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "display_topics(nmf_cv,count_vectorizer.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "* Use the vectors for the documents to train a Nearest Neighbors finder (not K Nearest Neighbors - \"Nearest Neighbor\")\n",
    "* Load in the \"test\" data from fetch20 for one of the categories you've used in the training data, and process it with the vectorizer and one of the LSA models.\n",
    "* Use your Nearest Neighbor model to find the 10 most similar documents to some document in the testing data, and return them as a recommendation for the user. Remember to choose a metric that makes sense in this context.\n",
    "* Repeat with the other LSA model and the NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "new_data = datasets.fetch_20newsgroups(subset='test', \n",
    "                                       categories=['rec.sport.baseball'], \n",
    "                                       remove=('headers', \n",
    "                                               'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_recommendations(first_article, model, vectorizer, training_vectors):\n",
    "    new_vec = model.transform(\n",
    "        vectorizer.transform([first_article]))\n",
    "    \n",
    "    # student section here\n",
    "    \n",
    "    \n",
    "    # student section ends here\n",
    "    return results[1][0]\n",
    "\n",
    "print(get_recommendations(new_data.data[2], lsa_cv, count_vectorizer, lsa_cv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def print_recommendations(first_article,recommend_list):\n",
    "    print(first_article)\n",
    "    print('\\n------\\n')\n",
    "    for resp in recommend_list:\n",
    "        print('\\n --- Result --- \\n')\n",
    "        print(ng_train.data[resp])\n",
    "        \n",
    "rec_list = get_recommendations(new_data.data[2], lsa_cv, count_vectorizer, lsa_cv_data)\n",
    "print_recommendations(new_data.data[2],rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rec_list = get_recommendations(new_data.data[2], lsa_tfidf, tfidf_vectorizer, lsa_tfidf_data)\n",
    "print_recommendations(new_data.data[2],rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rec_list = get_recommendations(new_data.data[2], nmf_cv, count_vectorizer, nmf_cv_data)\n",
    "print_recommendations(new_data.data[2],rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 4 (Optional, but recommended)\n",
    "\n",
    "* We can do the same thing with LDA as we have with Latent Space reductions. Create an LDA model with the fetch20 training data, with at least 4 topics.\n",
    "* Load in the fetch20 testing data for one of the categories only.\n",
    "* Use a nearest-neighbor model to recommend 10 documents to a user based on any other document, returning the number and text of the document for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn import datasets\n",
    "\n",
    "categories = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball']\n",
    "\n",
    "# student section here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# student section ends here\n",
    "\n",
    "X = count_vectorizer.fit_transform(ng_train.data)\n",
    "data = lda.fit_transform(X)\n",
    "\n",
    "test = lda.transform(count_vectorizer.transform(new_data.data))\n",
    "print(new_data.data[0])\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rec_list = get_recommendations(new_data.data[2], lda, count_vectorizer, data)\n",
    "print_recommendations(new_data.data[2],rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We can see that LDA allows us to do the same thing, but with a bit less success than the matrix reduction methods. In both cases, we end up with some understanding of \"how much of each topic\" is in the document. However, LDA is not as strong with small documents. The topics just aren't as well defined using the LDA methodology without lots of words to sample from in each document. With longer documents, LDA is excellent at pulling apart and understanding what topics are making up the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "* Open our second dataset at `data/ap/ap_split.txt` (Source: http://www.cs.columbia.edu/~blei/lda-c/). This is a dataset of articles from the associated press with no pre-determined scheme of topics. \n",
    "* Like last week, split and clean this dataset. You may use the same code from last week.\n",
    "* We want to build an article recommender for the Associated Press. Let's imagine that whatever input document we choose is the article the user is currently reading - we need to provide a list of a few documents to populate the \"you might also like...\" section of their website. Use the tools you developed above to make a production pipeline to accomplish this. \n",
    "    * **Inputs:** the ID number of the article (position in your list)\n",
    "    * **Outputs:** the IDs for the 5 articles most like the one being read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/ap_split.txt','r') as f:\n",
    "    raw_text = f.read()\n",
    "docs = raw_text.split('---')\n",
    "docs[1]\n",
    "\n",
    "import re\n",
    "match = re.compile(\"<[^>]*>\").search\n",
    "for i,doc in enumerate(docs):\n",
    "    final = []\n",
    "    temp = doc.split('\\n')\n",
    "    for line in temp:\n",
    "        if not match(line):\n",
    "            final.append(line)\n",
    "    docs[i] = ' '.join(final).strip().lower().replace(\"`\",\"\").replace(\"'\",\"\")\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Spawn and train the models to be put into the pipeline\n",
    "\n",
    "n_topics = 100\n",
    "n_iter = 10\n",
    "\n",
    "# student section here\n",
    "\n",
    "\n",
    "# student section ends here\n",
    "\n",
    "data = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_recommendations(docs, article_id, model, vectorizer, training_vectors):\n",
    "    # student section here\n",
    "    \n",
    "    \n",
    "    # student section ends here\n",
    "    return results[1][0]\n",
    "\n",
    "def print_recommendations(docs, recommend_list):\n",
    "    print(\"Recommended IDs: \", recommend_list)\n",
    "    for resp in recommend_list:\n",
    "        print('\\n --- Result --- \\n')\n",
    "        print(docs[resp])\n",
    "        \n",
    "rec_list = get_recommendations(docs, 0, lda, count_vectorizer, data)\n",
    "print_recommendations(docs, rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "In this result, we fed in an article about high school violence and received back recommendations about high school boycotts, teenagers marching against high school conditions, and terror attacks. Not the most cheery of subjects, but it's clear that the model is understanding the documents and recommending \"more of the same\" as we expect. Let's try with a different topic article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rec_list = get_recommendations(docs, 100, lda, count_vectorizer, data)\n",
    "print_recommendations(docs, rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Excellent! We put in an article about an airline acquisition that also talked about the president of the company. All of our recommendations are either business or airline related! This should work as a recommender - from here, all we'd need to do is link up the plumbing to some database of articles to make sure that whatever article we want to pull as a recommendation gets pulled properly and displayed. That's beyond the scope of this exercise (since we don't have a database), but is the last remaining step to make a functional article recommendation system. With more data, more improvements could be made... like adding a \"recent-ness\" filter and other steps... but for now, we've got a system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 6\n",
    "Let's build some clusters on our documents. We can already see that the relationship between documents in our latent space is meaningful, so clusters should be able to \"lump\" similar documents together in the topic space.\n",
    "\n",
    "* Spawn an LSA or NMF model with a proper vectorizer for the AP data - use 50 or more dimensions in the reduction (we'll want that for some visualizations).\n",
    "* Run a clustering algorithm on the reduced data, keeping track of the predicted cluster labels. \n",
    "* Use sklearn's t-SNE class to visualize the clusters in 2D.\n",
    "* Use the cluster ID for each document as the input, and return 10 other documents from the same cluster as a recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# student section here\n",
    "\n",
    "\n",
    "# student section ends here\n",
    "\n",
    "tfidf_data = tfidf_vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_comp = 50\n",
    "# student section here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# student section here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Let's chat about t-SNE really quickly: t-SNE is only used for displaying high dimensional data. NEVER convert to t-SNE and then cluster. Distances aren't preserved at all, only relationships to one another. So it's great for keeping the overall relationships in tact (as you can see below since the clusters tend to stay together), but the actual distances in 2D aren't meaningful and thus shouldn't be used to cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "tsne = TSNE().fit_transform(lsa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(tsne[:,0],tsne[:,1],c=plt.cm.rainbow(labels*10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We could thus also use the clustering labels as a recommendation (albeit, not as direct as using the nearest neighbors) by finding what cluster the document belongs to, then recommending other documents in that cluster randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_cluster_recommends(docs, labels, id_of_doc):\n",
    "    df = pd.DataFrame(labels, columns=['label'])\n",
    "    df = df[df['label'] == labels[id_of_doc]]\n",
    "    return list(df.sample(10).index)\n",
    "\n",
    "rec_list = get_cluster_recommends(docs, labels, 0)\n",
    "print_recommendations(docs,rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We can see it's not as direct, but when fed the same article on student violence, this method recommends education, student, and high school related articles. This will of course be somewhat randomized - but the methodology is sound. It also doesn't seem to be quite so \"direct\" in terms of choosing articles that are on EXACTLY the same topic. This method is not as popular, but can also be used to recommend articles when users are at risk of getting caught in a feedback loop of always seeing articles that are too similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (intel_nlp)",
   "language": "python",
   "name": "intel_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "30",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
