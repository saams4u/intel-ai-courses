{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-Trained Models\n",
    "In this exercise we will show how to load pre-trained models such as VGG16 and ResNet.  This is a fairly simple exercise designed to get you familiar with models like VGG and Resnet and the output they give.\n",
    "\n",
    "You will load in the VGG and ResNet models.  You will then use your laptop camera to take a picture.  Then you will run your picture through these models to see the results.\n",
    "\n",
    "You can also take pictures yourself and manually upload them.  Or find images on the internet and download them.  \n",
    "\n",
    "Look at the results for at least 5 different pictures and consider:\n",
    "\n",
    "- Did the models get the \"right\" answer?  Was the \"right\" answer on the list?\n",
    "- How confident was the prediction (did the top choice have a probability close to 1?)\n",
    "- How did the model handle pictures with multiple objects in them? (e.g. the rocking chair picture)\n",
    "- What were some of the \"wrong\" answers on the list?  Can you understand why the image classifier may have thought those other answers were correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install opencv if you haven't\n",
    "# conda install -c https://conda.binstar.org/menpo opencv3\n",
    "# pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image(camera):\n",
    "    retval, im = camera.read()\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_webcam_image(img_path):\n",
    "\n",
    "    try:\n",
    "        camera_port = 0\n",
    "        ramp_frames = 10\n",
    "    \n",
    "        camera = cv2.VideoCapture(camera_port)\n",
    "\n",
    "        for i in range(ramp_frames):\n",
    "            retval, im_camera = camera.read()\n",
    "\n",
    "        retval, im_camera = camera.read()\n",
    "\n",
    "        im = cv2.resize(im_camera, (224, 224)).astype(np.float32)\n",
    "        cv2.imwrite(img_path, im)\n",
    "        del (camera)\n",
    "        return True\n",
    "    except ValueError as e:\n",
    "        print(\"Image Capture Failed\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"webcam_test_img.png\"\n",
    "\n",
    "if save_webcam_image(img_path) is False:\n",
    "    # Webcam not active, use the rocking chair Image\n",
    "    img_path = \"rocking_chair.jpg\"\n",
    "    print(\"Using the Test Rocking Chair Image: {}\".format(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imread(img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 - Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet')\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility Function to Load Image, Preprocess input and Targets\n",
    "def predict_image(model, img_path, preprocess_input_fn, decode_predictions_fn, target_size=(224, 224)):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input_fn(x)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "    predictions_df = pd.DataFrame(decode_predictions_fn(preds, top=10)[0])\n",
    "    predictions_df.columns = [\"Predicted Class\", \"Name\", \"Probability\"]\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_path=\"rocking_chair.png\"  ## Uncomment this and put the path to your file here if desired\n",
    "# Predict Results\n",
    "predict_image(vgg16_model, img_path, vgg16.preprocess_input, vgg16.decode_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50 - Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a Resnet model and print the model summary (follow the same procedure as in VGGNet)\n",
    "\n",
    "# It will download the weights that might take a while\n",
    "# Also, the summary will be quite long, since Resnet50 is a much larger network than VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
