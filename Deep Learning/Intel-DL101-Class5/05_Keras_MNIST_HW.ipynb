{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Image Detection with Keras using MNIST data\n",
    "\n",
    "In this exercise we will work with image data: specifically the famous MNIST data set.  This data set contains 70,000 images of handwritten digits in grayscale (0=black, 255 = white).  The images are 28 pixels by 28 pixels for a total of 784 pixels.  This is quite small by image standards.  Also, the images are well centered and isolated.  This makes this problem solvable with standard fully connected neural nets without too much pre-work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this notebook, we will walk you through loading in the data, building a network, and training it.  Then it will be your turn to try different models and see if you can improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's explore the dataset a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data, shuffled and split between train and test sets (x_train and y_rain)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's just look at a particular example to see what is inside\n",
    "\n",
    "x_train[333]  ## Just a 28 x 28 numpy array of ints from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the corresponding label in the training set?\n",
    "y_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what this image actually looks like\n",
    "\n",
    "plt.imshow(x_train[333], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the shape of the np.array x_train\n",
    "# it is 3 dimensional.\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For our purposes, these images are just a vector of 784 inputs, so let's convert\n",
    "x_train = x_train.reshape(len(x_train), 28*28)\n",
    "x_test = x_test.reshape(len(x_test), 28*28)\n",
    "\n",
    "## Keras works with floats, so we must cast the numbers to floats\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "## Normalize the inputs so they are between 0 and 1\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train[333]  # now the digit k is represented by a 1 in the kth entry (0-indexed) of the length 10 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will build a model with two hidden layers of size 512\n",
    "# Fully connected inputs at each layer\n",
    "# We will use dropout of .2 to help regularize\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that this model has a LOT of parameters\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's compile the model\n",
    "learning_rate = .001\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "# note that `categorical cross entropy` is the natural generalization \n",
    "# of the loss function we had in binary classification case, to multi class case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's fit.\n",
    "\n",
    "batch_size = 128  # mini-batch with 128 examples\n",
    "epochs = 30\n",
    "history = model_1.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will use Keras evaluate function to evaluate performance on the test set\n",
    "\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('cross_entropy loss')\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.plot(history.history[\"acc\"],'r-x', label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_acc\"],'b-x', label=\"Validation Accuracy\")\n",
    "    ax.legend()\n",
    "    ax.set_title('accuracy')\n",
    "    ax.grid(True)\n",
    "    \n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is reasonably good performance, but we can do even better!  Next you will build an even bigger network and compare the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "### Your Turn: Build your own model\n",
    "Use the Keras \"Sequential\" functionality to build `model_2` with the following specifications:\n",
    "\n",
    "1. Two hidden layers.\n",
    "2. First hidden layer of size 400 and second of size 300\n",
    "3. Dropout of .4 at each layer\n",
    "4. How many parameters does your model have?  How does it compare with the previous model?\n",
    "4. Train this model for 20 epochs with RMSProp at a learning rate of .001 and a batch size of 128\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Build your model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Think about the following questions\n",
    "\n",
    "1) How do model_1 and model_2 compare?  Which do you prefer?  If you were going to put one into production, which would you choose and why?\n",
    "\n",
    "2) Compare the trajectories of the loss function on the training set and test set for each model?  How do they compare?  What does that suggest about each model?  Do the same for accuracy?  Which do you think is more meaningful, the loss or the accuracy?\n",
    "\n",
    "3) Suggest an improvement to one of the models (changing structure, learning rate, number of epochs, etc.) that you think will result in a better model.  Try it out below?  Did it improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
