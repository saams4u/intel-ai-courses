{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines and Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be using the wine quality data set for these exercises. This data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-10T00:04:57.164238Z",
     "start_time": "2017-04-09T20:04:57.158472-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "#Please set the path below as per your system data folder location\n",
    "#data_path = ['..', 'data']\n",
    "data_path = ['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Import the data.\n",
    "* Create the target variable `y` as a 1/0 column where 1 means red.\n",
    "* Create a `pairplot` for the dataset.\n",
    "* Create a bar plot showing the correlations between each column and `y`\n",
    "* Pick the most 2 correlated fields (using the absolute value of correlations) and create `X`\n",
    "* Use MinMaxScaler to scale `X`. Note that this will output a np.array. Make it a DataFrame again and rename the columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-10T00:04:57.731417Z",
     "start_time": "2017-04-09T20:04:57.168224-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = os.sep.join(data_path + ['Wine_Quality_Data.csv'])\n",
    "data = pd.read_csv(filepath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-10T00:04:57.769148Z",
     "start_time": "2017-04-09T20:04:57.734768-04:00"
    }
   },
   "outputs": [],
   "source": [
    "y = (data['color'] == 'red').astype(int)\n",
    "fields = list(data.columns[:-1])  # everything except \"color\"\n",
    "correlations = data[fields].corrwith(y)\n",
    "correlations.sort_values(inplace=True)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_palette('dark')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue='color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = correlations.plot(kind='bar')\n",
    "ax.set(ylim=[-1, 1], ylabel='pearson correlation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "fields = correlations.map(abs).sort_values().iloc[-2:].index\n",
    "print(fields)\n",
    "X = data[fields]\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "The goal for this question is to look at the decision boundary of a LinearSVC classifier on this dataset. Check out [this example](http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py) in sklearn's documentation. \n",
    "\n",
    "* Fit a Linear Support Vector Machine Classifier to `X`, `y`.\n",
    "* Pick 300 samples from `X`. Get the corresponding `y` value. Store them in variables `X_color` and `y_color`. This is because original dataset is too large and it produces a crowded plot.\n",
    "* Modify `y_color` so that it has the value \"red\" instead of 1 and 'yellow' instead of 0.\n",
    "* Scatter plot X_color's columns. Use the keyword argument \"color=y_color\" to color code samples.\n",
    "* Use the code snippet below to plot the decision surface in a color coded way.\n",
    "\n",
    "```python\n",
    "x_axis, y_axis = np.arange(0, 1, .005), np.arange(0, 1, .005)\n",
    "xx, yy = np.meshgrid(x_axis, y_axis)\n",
    "xx_ravel = xx.ravel()\n",
    "yy_ravel = yy.ravel()\n",
    "X_grid = pd.DataFrame([xx_ravel, yy_ravel]).T\n",
    "y_grid_predictions = *[YOUR MODEL]*.predict(X_grid)\n",
    "y_grid_predictions = y_grid_predictions.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, y_grid_predictions, cmap=plt.cm.autumn_r, alpha=.3)\n",
    "```\n",
    "\n",
    "Feel free to experiment with different parameter choices for LinearSVC and see the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "LSVC = LinearSVC()\n",
    "LSVC.fit(X, y)\n",
    "\n",
    "X_color = X.sample(300, random_state=45)\n",
    "y_color = y.loc[X_color.index]\n",
    "y_color = y_color.map(lambda r: 'red' if r == 1 else 'yellow')\n",
    "ax = plt.axes()\n",
    "ax.scatter(\n",
    "    X_color.iloc[:, 0], X_color.iloc[:, 1],\n",
    "    color=y_color, alpha=1)\n",
    "# -----------\n",
    "x_axis, y_axis = np.arange(0, 1.005, .005), np.arange(0, 1.005, .005)\n",
    "xx, yy = np.meshgrid(x_axis, y_axis)\n",
    "xx_ravel = xx.ravel()\n",
    "yy_ravel = yy.ravel()\n",
    "X_grid = pd.DataFrame([xx_ravel, yy_ravel]).T\n",
    "y_grid_predictions = LSVC.predict(X_grid)\n",
    "y_grid_predictions = y_grid_predictions.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, y_grid_predictions, cmap=plt.cm.autumn_r, alpha=.3)\n",
    "# -----------\n",
    "ax.set(\n",
    "    xlabel=fields[0],\n",
    "    ylabel=fields[1],\n",
    "    xlim=[0, 1],\n",
    "    ylim=[0, 1],\n",
    "    title='decision boundary for LinearSVC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's now fit a Gaussian kernel SVC and see how the decision boundary changes.\n",
    "\n",
    "* Consolidate the code snippets in Question 2 into one function which takes in an estimator, `X` and `y`, and produces the final plot with decision boundary. The steps are:\n",
    "    <ol>\n",
    "     <li> fit model\n",
    "     <li> get sample 300 records from X and the corresponding y's\n",
    "     <li> create grid, predict, plot using ax.contourf\n",
    "     <li> add on the scatter plot\n",
    "    </ol>\n",
    "* After copying and pasting code, make sure the finished function uses your input `estimator` and not the LinearSVC model you built.\n",
    "* For the following values of `gamma`, create a Gaussian Kernel SVC and plot the decision boundary.  \n",
    "`gammas = [.5, 1, 2, 10]`\n",
    "* Holding `gamma` constant, for various values of `C`, plot the decision boundary. You may try  \n",
    "`Cs = [.1, 1, 10]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    X_color = X.sample(300)\n",
    "    y_color = y.loc[X_color.index]\n",
    "    y_color = y_color.map(lambda r: 'red' if r == 1 else 'yellow')\n",
    "    x_axis, y_axis = np.arange(0, 1, .005), np.arange(0, 1, .005)\n",
    "    xx, yy = np.meshgrid(x_axis, y_axis)\n",
    "    xx_ravel = xx.ravel()\n",
    "    yy_ravel = yy.ravel()\n",
    "    X_grid = pd.DataFrame([xx_ravel, yy_ravel]).T\n",
    "    y_grid_predictions = estimator.predict(X_grid)\n",
    "    y_grid_predictions = y_grid_predictions.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.contourf(xx, yy, y_grid_predictions, cmap=plt.cm.autumn_r, alpha=.3)\n",
    "    ax.scatter(X_color.iloc[:, 0], X_color.iloc[:, 1], color=y_color, alpha=1)\n",
    "    ax.set(\n",
    "        xlabel=fields[0],\n",
    "        ylabel=fields[1],\n",
    "        title=str(estimator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "gammas = [.5, 1, 2, 10]\n",
    "for gamma in gammas:\n",
    "    SVC_Gaussian = SVC(kernel='rbf', gamma=gamma)\n",
    "    plot_decision_boundary(SVC_Gaussian, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [.1, 1, 10]\n",
    "for C in Cs:\n",
    "    SVC_Gaussian = SVC(kernel='rbf', gamma=2, C=C)\n",
    "    plot_decision_boundary(SVC_Gaussian, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3A\n",
    "\n",
    "Let's now fit a Polynomial kernel SVC with degree 3 and see how the decision boundary changes.\n",
    "\n",
    "* Use the plot decision boundary function from the previous question and try the Polynomial Kernel SVC\n",
    "* For various values of `C`, plot the decision boundary. You may try  \n",
    "`Cs = [10,20,100,200]`\n",
    "* Try to find out a C value that gives the best possible decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try with Polynomial kernel SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 4\n",
    "\n",
    "In this question, we will compare the fitting times between SVC vs Nystroem with rbf kernel.  \n",
    "<br><br>\n",
    "Jupyter Notebooks provide a useful magic function **`%timeit`** which executes a line and prints out the time it took to fit. If you type **`%%timeit`** in the beginning of the cell, then it will run the whole cell and output the running time.\n",
    "\n",
    "* Re-load the wine quality data if you made changes to the original.\n",
    "* Create `y` from data.color, and `X` from the rest of the columns.\n",
    "* Use `%%timeit` to get the time for fitting an SVC with rbf kernel.\n",
    "* Use `%%timeit` to get the time for the following: fit_transform the data with Nystroem and then fit a SGDClassifier.\n",
    "\n",
    "Nystroem+SGD will take much shorter to fit. This difference will be more pronounced if the dataset was bigger.\n",
    "\n",
    "* Make 5 copies of X and concatenate them\n",
    "* Make 5 copies of y and concatenate them\n",
    "* Compare the time it takes to fit the both methods above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "y = data.color == 'red'\n",
    "X = data[data.columns[:-1]]\n",
    "\n",
    "kwargs = {'kernel': 'rbf'}\n",
    "svc = SVC(**kwargs)\n",
    "nystroem = Nystroem(**kwargs)\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "X_transformed = nystroem.fit_transform(X)\n",
    "sgd.fit(X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.concat([X]*5)\n",
    "y2 = pd.concat([y]*5)\n",
    "\n",
    "print(X2.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit svc.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "X2_transformed = nystroem.fit_transform(X2)\n",
    "sgd.fit(X2_transformed, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Try Tuning hyper-parameters for the svm kernal using GridSearchCV\n",
    "\n",
    "* Take the complete dataset\n",
    "* Define y as data.color = 'red'\n",
    "* Remaining columns as X\n",
    "* Do a test and train split\n",
    "* Set parameters for cross validation. Do this for as many values of gamma and C\n",
    "* Using gridsearchcv to run through the data using the various parameters values\n",
    "* Get the mean and standard deviation on the set for the various combination of gamma and C values\n",
    "* print the best parameters in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "   Use the model from previous question to predict \n",
    " \n",
    " * Perform the prediction on the test set  \n",
    " * Print confusion matrix, accuracy and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
